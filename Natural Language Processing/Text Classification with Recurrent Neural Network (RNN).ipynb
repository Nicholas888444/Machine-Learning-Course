{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with Recurrent Neural Network (RNN)\n",
    "\n",
    "In this tutorial, we will illustrate how to conduct text classification task with Recurrent Neural Network (RNN).\n",
    "\n",
    "Recurrent Neural Network (RNN) is a type of artificial neural network designed to process sequential data and is particularly well-suited for tasks such as time series prediction, sequence generation, language modeling, and natural language processing.\n",
    "\n",
    "An introduction to recurrent neural network can be found at : https://en.wikipedia.org/wiki/Recurrent_neural_network \n",
    "\n",
    "We will use Google **TensorFlow** to build an RNN. Compared with PyTorch, Tensorflow makes it easier for building large and complex neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.26.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.62.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\nick8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "# Run the following command to install tensorflow\n",
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nick8\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "# Verify Installation:\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Process Dataset\n",
    "In this tutorial, we still use the IMDB review dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "\n",
    "# Convert sentiment labels to numerical values\n",
    "df['sentiment'] = df['sentiment'].map({'negative': 0, 'positive': 1})\n",
    "\n",
    "# Split the data into features (reviews) and targets (sentiments)\n",
    "X = df['review']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing and Padding Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes a Tokenizer object with a maximum vocabulary size of 10,000 words.\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "\n",
    "# Fits the tokenizer on the text data to generate the word index.\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 1\n",
      "and 2\n",
      "a 3\n",
      "of 4\n",
      "to 5\n",
      "is 6\n",
      "br 7\n",
      "in 8\n",
      "it 9\n",
      "i 10\n",
      "this 11\n",
      "that 12\n",
      "was 13\n",
      "as 14\n",
      "for 15\n",
      "with 16\n",
      "movie 17\n",
      "but 18\n",
      "film 19\n",
      "on 20\n",
      "not 21\n",
      "you 22\n",
      "are 23\n",
      "his 24\n",
      "have 25\n",
      "be 26\n",
      "one 27\n",
      "he 28\n",
      "all 29\n",
      "at 30\n",
      "by 31\n",
      "an 32\n",
      "they 33\n",
      "so 34\n",
      "who 35\n",
      "from 36\n",
      "like 37\n",
      "or 38\n",
      "just 39\n",
      "her 40\n",
      "out 41\n",
      "about 42\n",
      "if 43\n",
      "it's 44\n",
      "has 45\n",
      "there 46\n",
      "some 47\n",
      "what 48\n",
      "good 49\n",
      "when 50\n",
      "more 51\n",
      "very 52\n",
      "up 53\n",
      "no 54\n",
      "time 55\n",
      "my 56\n",
      "even 57\n",
      "would 58\n",
      "she 59\n",
      "which 60\n",
      "only 61\n",
      "really 62\n",
      "see 63\n",
      "story 64\n",
      "their 65\n",
      "had 66\n",
      "can 67\n",
      "me 68\n",
      "well 69\n",
      "were 70\n",
      "than 71\n",
      "much 72\n",
      "we 73\n",
      "bad 74\n",
      "been 75\n",
      "get 76\n",
      "do 77\n",
      "great 78\n",
      "other 79\n",
      "will 80\n",
      "also 81\n",
      "into 82\n",
      "people 83\n",
      "because 84\n",
      "how 85\n",
      "first 86\n",
      "him 87\n",
      "most 88\n",
      "don't 89\n",
      "made 90\n",
      "then 91\n",
      "its 92\n",
      "them 93\n",
      "make 94\n",
      "way 95\n",
      "too 96\n",
      "movies 97\n",
      "could 98\n",
      "any 99\n",
      "after 100\n",
      "think 101\n",
      "characters 102\n",
      "watch 103\n",
      "films 104\n",
      "two 105\n",
      "many 106\n",
      "seen 107\n",
      "character 108\n",
      "being 109\n",
      "never 110\n",
      "plot 111\n",
      "love 112\n",
      "acting 113\n",
      "life 114\n",
      "did 115\n",
      "best 116\n",
      "where 117\n",
      "know 118\n",
      "show 119\n",
      "little 120\n",
      "over 121\n",
      "off 122\n",
      "ever 123\n",
      "does 124\n",
      "your 125\n",
      "better 126\n",
      "end 127\n",
      "man 128\n",
      "scene 129\n",
      "still 130\n",
      "say 131\n",
      "these 132\n",
      "here 133\n",
      "scenes 134\n",
      "why 135\n",
      "while 136\n",
      "something 137\n",
      "such 138\n",
      "go 139\n",
      "through 140\n",
      "back 141\n",
      "should 142\n",
      "those 143\n",
      "real 144\n",
      "i'm 145\n",
      "now 146\n",
      "watching 147\n",
      "thing 148\n",
      "doesn't 149\n",
      "actors 150\n",
      "though 151\n",
      "funny 152\n",
      "years 153\n",
      "didn't 154\n",
      "old 155\n",
      "10 156\n",
      "another 157\n",
      "work 158\n",
      "before 159\n",
      "actually 160\n",
      "nothing 161\n",
      "makes 162\n",
      "look 163\n",
      "director 164\n",
      "find 165\n",
      "going 166\n",
      "same 167\n",
      "new 168\n",
      "lot 169\n",
      "every 170\n",
      "few 171\n",
      "again 172\n",
      "part 173\n",
      "cast 174\n",
      "down 175\n",
      "us 176\n",
      "things 177\n",
      "want 178\n",
      "quite 179\n",
      "pretty 180\n",
      "world 181\n",
      "horror 182\n",
      "around 183\n",
      "seems 184\n",
      "can't 185\n",
      "young 186\n",
      "take 187\n",
      "however 188\n",
      "got 189\n",
      "thought 190\n",
      "big 191\n",
      "fact 192\n",
      "enough 193\n",
      "long 194\n",
      "both 195\n",
      "that's 196\n",
      "give 197\n",
      "i've 198\n",
      "own 199\n",
      "may 200\n",
      "between 201\n",
      "comedy 202\n",
      "right 203\n",
      "series 204\n",
      "action 205\n",
      "must 206\n",
      "music 207\n",
      "without 208\n",
      "times 209\n",
      "saw 210\n",
      "always 211\n",
      "original 212\n",
      "isn't 213\n",
      "role 214\n",
      "come 215\n",
      "almost 216\n",
      "gets 217\n",
      "interesting 218\n",
      "guy 219\n",
      "point 220\n",
      "done 221\n",
      "there's 222\n",
      "whole 223\n",
      "least 224\n",
      "far 225\n",
      "bit 226\n",
      "script 227\n",
      "minutes 228\n",
      "feel 229\n",
      "2 230\n",
      "anything 231\n",
      "making 232\n",
      "might 233\n",
      "since 234\n",
      "am 235\n",
      "family 236\n",
      "he's 237\n",
      "last 238\n",
      "probably 239\n",
      "tv 240\n",
      "performance 241\n",
      "kind 242\n",
      "away 243\n",
      "yet 244\n",
      "fun 245\n",
      "worst 246\n",
      "sure 247\n",
      "rather 248\n",
      "hard 249\n",
      "anyone 250\n",
      "girl 251\n",
      "each 252\n",
      "played 253\n",
      "day 254\n",
      "found 255\n",
      "looking 256\n",
      "woman 257\n",
      "screen 258\n",
      "although 259\n",
      "our 260\n",
      "especially 261\n",
      "believe 262\n",
      "having 263\n",
      "trying 264\n",
      "course 265\n",
      "dvd 266\n",
      "everything 267\n",
      "set 268\n",
      "goes 269\n",
      "comes 270\n",
      "put 271\n",
      "ending 272\n",
      "maybe 273\n",
      "place 274\n",
      "book 275\n",
      "shows 276\n",
      "three 277\n",
      "worth 278\n",
      "different 279\n",
      "main 280\n",
      "once 281\n",
      "sense 282\n",
      "american 283\n",
      "reason 284\n",
      "looks 285\n",
      "effects 286\n",
      "watched 287\n",
      "play 288\n",
      "true 289\n",
      "money 290\n",
      "actor 291\n",
      "wasn't 292\n",
      "job 293\n",
      "together 294\n",
      "war 295\n",
      "someone 296\n",
      "plays 297\n",
      "instead 298\n",
      "high 299\n",
      "during 300\n",
      "year 301\n",
      "said 302\n",
      "half 303\n",
      "everyone 304\n",
      "later 305\n",
      "takes 306\n",
      "1 307\n",
      "seem 308\n",
      "audience 309\n",
      "special 310\n",
      "beautiful 311\n",
      "left 312\n",
      "himself 313\n",
      "seeing 314\n",
      "john 315\n",
      "night 316\n",
      "black 317\n",
      "version 318\n",
      "shot 319\n",
      "excellent 320\n",
      "idea 321\n",
      "house 322\n",
      "mind 323\n",
      "star 324\n",
      "wife 325\n",
      "fan 326\n",
      "death 327\n",
      "used 328\n",
      "else 329\n",
      "simply 330\n",
      "nice 331\n",
      "budget 332\n",
      "poor 333\n",
      "short 334\n",
      "completely 335\n",
      "second 336\n",
      "you're 337\n",
      "3 338\n",
      "read 339\n",
      "less 340\n",
      "along 341\n",
      "top 342\n",
      "help 343\n",
      "home 344\n",
      "men 345\n",
      "either 346\n",
      "line 347\n",
      "boring 348\n",
      "dead 349\n",
      "friends 350\n",
      "kids 351\n",
      "try 352\n",
      "production 353\n",
      "enjoy 354\n",
      "camera 355\n",
      "use 356\n",
      "wrong 357\n",
      "given 358\n",
      "low 359\n",
      "classic 360\n",
      "father 361\n",
      "need 362\n",
      "full 363\n",
      "stupid 364\n",
      "next 365\n",
      "until 366\n",
      "performances 367\n",
      "school 368\n",
      "hollywood 369\n",
      "rest 370\n",
      "truly 371\n",
      "awful 372\n",
      "video 373\n",
      "couple 374\n",
      "start 375\n",
      "sex 376\n",
      "recommend 377\n",
      "women 378\n",
      "let 379\n",
      "tell 380\n",
      "terrible 381\n",
      "remember 382\n",
      "mean 383\n",
      "came 384\n",
      "getting 385\n",
      "understand 386\n",
      "perhaps 387\n",
      "moments 388\n",
      "name 389\n",
      "keep 390\n",
      "face 391\n",
      "itself 392\n",
      "wonderful 393\n",
      "playing 394\n",
      "human 395\n",
      "style 396\n",
      "small 397\n",
      "episode 398\n",
      "perfect 399\n",
      "others 400\n",
      "person 401\n",
      "doing 402\n",
      "often 403\n",
      "early 404\n",
      "stars 405\n",
      "definitely 406\n",
      "written 407\n",
      "head 408\n",
      "lines 409\n",
      "dialogue 410\n",
      "gives 411\n",
      "piece 412\n",
      "couldn't 413\n",
      "went 414\n",
      "finally 415\n",
      "mother 416\n",
      "case 417\n",
      "title 418\n",
      "absolutely 419\n",
      "boy 420\n",
      "live 421\n",
      "yes 422\n",
      "laugh 423\n",
      "certainly 424\n",
      "liked 425\n",
      "become 426\n",
      "entertaining 427\n",
      "worse 428\n",
      "oh 429\n",
      "sort 430\n",
      "loved 431\n",
      "lost 432\n",
      "called 433\n",
      "hope 434\n",
      "picture 435\n",
      "felt 436\n",
      "overall 437\n",
      "entire 438\n",
      "mr 439\n",
      "several 440\n",
      "based 441\n",
      "supposed 442\n",
      "cinema 443\n",
      "friend 444\n",
      "guys 445\n",
      "sound 446\n",
      "5 447\n",
      "problem 448\n",
      "drama 449\n",
      "against 450\n",
      "waste 451\n",
      "white 452\n",
      "beginning 453\n",
      "4 454\n",
      "fans 455\n",
      "totally 456\n",
      "dark 457\n",
      "care 458\n",
      "direction 459\n",
      "humor 460\n",
      "wanted 461\n",
      "she's 462\n",
      "seemed 463\n",
      "under 464\n",
      "game 465\n",
      "children 466\n",
      "despite 467\n",
      "lives 468\n",
      "lead 469\n",
      "guess 470\n",
      "example 471\n",
      "already 472\n",
      "final 473\n",
      "you'll 474\n",
      "throughout 475\n",
      "evil 476\n",
      "turn 477\n",
      "becomes 478\n",
      "unfortunately 479\n",
      "able 480\n",
      "quality 481\n",
      "i'd 482\n",
      "days 483\n",
      "history 484\n",
      "fine 485\n",
      "side 486\n",
      "wants 487\n",
      "horrible 488\n",
      "heart 489\n",
      "writing 490\n",
      "amazing 491\n",
      "b 492\n",
      "flick 493\n",
      "killer 494\n",
      "run 495\n",
      "son 496\n",
      "Â– 497\n",
      "michael 498\n",
      "works 499\n",
      "close 500\n",
      "they're 501\n",
      "act 502\n",
      "art 503\n",
      "kill 504\n",
      "matter 505\n",
      "etc 506\n",
      "tries 507\n",
      "won't 508\n",
      "past 509\n",
      "town 510\n",
      "enjoyed 511\n",
      "turns 512\n",
      "brilliant 513\n",
      "gave 514\n",
      "behind 515\n",
      "parts 516\n",
      "stuff 517\n",
      "genre 518\n",
      "eyes 519\n",
      "car 520\n",
      "favorite 521\n",
      "directed 522\n",
      "late 523\n",
      "hand 524\n",
      "expect 525\n",
      "soon 526\n",
      "hour 527\n",
      "obviously 528\n",
      "themselves 529\n",
      "sometimes 530\n",
      "killed 531\n",
      "thinking 532\n",
      "actress 533\n",
      "child 534\n",
      "girls 535\n",
      "viewer 536\n",
      "starts 537\n",
      "city 538\n",
      "myself 539\n",
      "decent 540\n",
      "highly 541\n",
      "stop 542\n",
      "type 543\n",
      "self 544\n",
      "god 545\n",
      "says 546\n",
      "group 547\n",
      "anyway 548\n",
      "voice 549\n",
      "took 550\n",
      "known 551\n",
      "blood 552\n",
      "kid 553\n",
      "heard 554\n",
      "happens 555\n",
      "except 556\n",
      "fight 557\n",
      "feeling 558\n",
      "experience 559\n",
      "coming 560\n",
      "slow 561\n",
      "daughter 562\n",
      "writer 563\n",
      "stories 564\n",
      "moment 565\n",
      "leave 566\n",
      "told 567\n",
      "extremely 568\n",
      "score 569\n",
      "violence 570\n",
      "involved 571\n",
      "police 572\n",
      "strong 573\n",
      "lack 574\n",
      "chance 575\n",
      "cannot 576\n",
      "hit 577\n",
      "roles 578\n",
      "hilarious 579\n",
      "s 580\n",
      "wonder 581\n",
      "happen 582\n",
      "particularly 583\n",
      "ok 584\n",
      "including 585\n",
      "save 586\n",
      "living 587\n",
      "looked 588\n",
      "wouldn't 589\n",
      "crap 590\n",
      "please 591\n",
      "simple 592\n",
      "murder 593\n",
      "cool 594\n",
      "obvious 595\n",
      "happened 596\n",
      "complete 597\n",
      "cut 598\n",
      "serious 599\n",
      "age 600\n",
      "gore 601\n",
      "attempt 602\n",
      "hell 603\n",
      "ago 604\n",
      "song 605\n",
      "shown 606\n",
      "taken 607\n",
      "english 608\n",
      "james 609\n",
      "robert 610\n",
      "david 611\n",
      "seriously 612\n",
      "released 613\n",
      "reality 614\n",
      "opening 615\n",
      "jokes 616\n",
      "interest 617\n",
      "across 618\n",
      "none 619\n",
      "hero 620\n",
      "exactly 621\n",
      "today 622\n",
      "possible 623\n",
      "alone 624\n",
      "sad 625\n",
      "brother 626\n",
      "number 627\n",
      "career 628\n",
      "saying 629\n",
      "film's 630\n",
      "usually 631\n",
      "hours 632\n",
      "cinematography 633\n",
      "talent 634\n",
      "view 635\n",
      "annoying 636\n",
      "running 637\n",
      "yourself 638\n",
      "relationship 639\n",
      "documentary 640\n",
      "wish 641\n",
      "order 642\n",
      "huge 643\n",
      "shots 644\n",
      "whose 645\n",
      "ridiculous 646\n",
      "taking 647\n",
      "important 648\n",
      "light 649\n",
      "body 650\n",
      "middle 651\n",
      "level 652\n",
      "ends 653\n",
      "started 654\n",
      "female 655\n",
      "call 656\n",
      "i'll 657\n",
      "husband 658\n",
      "four 659\n",
      "power 660\n",
      "word 661\n",
      "turned 662\n",
      "major 663\n",
      "opinion 664\n",
      "change 665\n",
      "mostly 666\n",
      "usual 667\n",
      "scary 668\n",
      "silly 669\n",
      "rating 670\n",
      "beyond 671\n",
      "somewhat 672\n",
      "happy 673\n",
      "ones 674\n",
      "words 675\n",
      "room 676\n",
      "knows 677\n",
      "knew 678\n",
      "country 679\n",
      "disappointed 680\n",
      "talking 681\n",
      "novel 682\n",
      "apparently 683\n",
      "non 684\n",
      "strange 685\n",
      "upon 686\n",
      "attention 687\n",
      "basically 688\n",
      "single 689\n",
      "finds 690\n",
      "cheap 691\n",
      "modern 692\n",
      "due 693\n",
      "jack 694\n",
      "television 695\n",
      "musical 696\n",
      "problems 697\n",
      "miss 698\n",
      "episodes 699\n",
      "clearly 700\n",
      "local 701\n",
      "7 702\n",
      "british 703\n",
      "thriller 704\n",
      "talk 705\n",
      "events 706\n",
      "sequence 707\n",
      "five 708\n",
      "aren't 709\n",
      "class 710\n",
      "french 711\n",
      "moving 712\n",
      "ten 713\n",
      "fast 714\n",
      "earth 715\n",
      "review 716\n",
      "tells 717\n",
      "predictable 718\n",
      "songs 719\n",
      "team 720\n",
      "comic 721\n",
      "straight 722\n",
      "8 723\n",
      "whether 724\n",
      "die 725\n",
      "add 726\n",
      "dialog 727\n",
      "entertainment 728\n",
      "above 729\n",
      "sets 730\n",
      "future 731\n",
      "enjoyable 732\n",
      "appears 733\n",
      "near 734\n",
      "space 735\n",
      "easily 736\n",
      "hate 737\n",
      "soundtrack 738\n",
      "bring 739\n",
      "giving 740\n",
      "lots 741\n",
      "similar 742\n",
      "romantic 743\n",
      "george 744\n",
      "supporting 745\n",
      "release 746\n",
      "mention 747\n",
      "within 748\n",
      "filmed 749\n",
      "message 750\n",
      "sequel 751\n",
      "clear 752\n",
      "falls 753\n",
      "haven't 754\n",
      "needs 755\n",
      "dull 756\n",
      "suspense 757\n",
      "bunch 758\n",
      "eye 759\n",
      "surprised 760\n",
      "showing 761\n",
      "tried 762\n",
      "sorry 763\n",
      "certain 764\n",
      "working 765\n",
      "easy 766\n",
      "ways 767\n",
      "theme 768\n",
      "theater 769\n",
      "among 770\n",
      "named 771\n",
      "what's 772\n",
      "storyline 773\n",
      "monster 774\n",
      "king 775\n",
      "stay 776\n",
      "effort 777\n",
      "minute 778\n",
      "fall 779\n",
      "stand 780\n",
      "gone 781\n",
      "rock 782\n",
      "using 783\n",
      "9 784\n",
      "feature 785\n",
      "comments 786\n",
      "buy 787\n",
      "' 788\n",
      "typical 789\n",
      "t 790\n",
      "editing 791\n",
      "sister 792\n",
      "tale 793\n",
      "avoid 794\n",
      "dr 795\n",
      "mystery 796\n",
      "deal 797\n",
      "doubt 798\n",
      "fantastic 799\n",
      "kept 800\n",
      "nearly 801\n",
      "feels 802\n",
      "subject 803\n",
      "okay 804\n",
      "viewing 805\n",
      "elements 806\n",
      "oscar 807\n",
      "check 808\n",
      "points 809\n",
      "realistic 810\n",
      "means 811\n",
      "greatest 812\n",
      "herself 813\n",
      "parents 814\n",
      "famous 815\n",
      "imagine 816\n",
      "rent 817\n",
      "viewers 818\n",
      "richard 819\n",
      "crime 820\n",
      "form 821\n",
      "peter 822\n",
      "actual 823\n",
      "lady 824\n",
      "general 825\n",
      "dog 826\n",
      "follow 827\n",
      "believable 828\n",
      "period 829\n",
      "red 830\n",
      "brought 831\n",
      "move 832\n",
      "material 833\n",
      "forget 834\n",
      "somehow 835\n",
      "begins 836\n",
      "re 837\n",
      "reviews 838\n",
      "animation 839\n",
      "paul 840\n",
      "you've 841\n",
      "leads 842\n",
      "weak 843\n",
      "figure 844\n",
      "surprise 845\n",
      "hear 846\n",
      "sit 847\n",
      "average 848\n",
      "open 849\n",
      "sequences 850\n",
      "killing 851\n",
      "atmosphere 852\n",
      "eventually 853\n",
      "tom 854\n",
      "learn 855\n",
      "premise 856\n",
      "wait 857\n",
      "20 858\n",
      "sci 859\n",
      "deep 860\n",
      "fi 861\n",
      "expected 862\n",
      "whatever 863\n",
      "indeed 864\n",
      "lame 865\n",
      "poorly 866\n",
      "particular 867\n",
      "note 868\n",
      "dance 869\n",
      "imdb 870\n",
      "shame 871\n",
      "situation 872\n",
      "third 873\n",
      "york 874\n",
      "box 875\n",
      "truth 876\n",
      "decided 877\n",
      "free 878\n",
      "hot 879\n",
      "who's 880\n",
      "difficult 881\n",
      "needed 882\n",
      "season 883\n",
      "acted 884\n",
      "leaves 885\n",
      "unless 886\n",
      "romance 887\n",
      "emotional 888\n",
      "possibly 889\n",
      "gay 890\n",
      "sexual 891\n",
      "boys 892\n",
      "footage 893\n",
      "write 894\n",
      "western 895\n",
      "credits 896\n",
      "forced 897\n",
      "memorable 898\n",
      "doctor 899\n",
      "reading 900\n",
      "became 901\n",
      "otherwise 902\n",
      "air 903\n",
      "begin 904\n",
      "de 905\n",
      "crew 906\n",
      "question 907\n",
      "meet 908\n",
      "society 909\n",
      "male 910\n",
      "let's 911\n",
      "meets 912\n",
      "plus 913\n",
      "cheesy 914\n",
      "hands 915\n",
      "superb 916\n",
      "screenplay 917\n",
      "beauty 918\n",
      "interested 919\n",
      "street 920\n",
      "features 921\n",
      "perfectly 922\n",
      "masterpiece 923\n",
      "whom 924\n",
      "laughs 925\n",
      "nature 926\n",
      "stage 927\n",
      "effect 928\n",
      "forward 929\n",
      "comment 930\n",
      "nor 931\n",
      "previous 932\n",
      "e 933\n",
      "badly 934\n",
      "sounds 935\n",
      "japanese 936\n",
      "weird 937\n",
      "island 938\n",
      "inside 939\n",
      "personal 940\n",
      "quickly 941\n",
      "total 942\n",
      "keeps 943\n",
      "towards 944\n",
      "america 945\n",
      "result 946\n",
      "crazy 947\n",
      "battle 948\n",
      "worked 949\n",
      "incredibly 950\n",
      "setting 951\n",
      "earlier 952\n",
      "background 953\n",
      "mess 954\n",
      "cop 955\n",
      "writers 956\n",
      "fire 957\n",
      "copy 958\n",
      "realize 959\n",
      "dumb 960\n",
      "unique 961\n",
      "powerful 962\n",
      "mark 963\n",
      "lee 964\n",
      "business 965\n",
      "rate 966\n",
      "older 967\n",
      "dramatic 968\n",
      "pay 969\n",
      "following 970\n",
      "girlfriend 971\n",
      "directors 972\n",
      "joke 973\n",
      "plenty 974\n",
      "directing 975\n",
      "various 976\n",
      "baby 977\n",
      "creepy 978\n",
      "development 979\n",
      "appear 980\n",
      "brings 981\n",
      "front 982\n",
      "dream 983\n",
      "ask 984\n",
      "water 985\n",
      "rich 986\n",
      "bill 987\n",
      "admit 988\n",
      "apart 989\n",
      "joe 990\n",
      "political 991\n",
      "fairly 992\n",
      "leading 993\n",
      "reasons 994\n",
      "spent 995\n",
      "portrayed 996\n",
      "telling 997\n",
      "cover 998\n",
      "outside 999\n",
      "fighting 1000\n",
      "present 1001\n"
     ]
    }
   ],
   "source": [
    "# Display the word index\n",
    "word_index = tokenizer.word_index\n",
    "i = 0\n",
    "for word in word_index:\n",
    "    print(word, word_index[word])\n",
    "    i += 1\n",
    "    if (i > 1000):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Converts the text data into sequences of integers based on the word index.\n",
    "X = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 4, 1, 79, 2102, 45, 1072, 12, 100, 147, 39, 307, 3184, 398, 474, 26, 3195, 33, 23, 203, 14, 11, 6, 621, 48, 596, 16, 68, 7, 7, 1, 86, 148, 12, 3241, 68, 42, 3184, 13, 92, 5398, 2, 134, 4, 570, 60, 268, 8, 203, 36, 1, 661, 139, 1740, 68, 11, 6, 21, 3, 119, 15, 1, 7888, 2333, 38, 11, 119, 2595, 54, 5911, 16, 5510, 5, 1479, 376, 38, 570, 92, 6, 3804, 8, 1, 360, 356, 4, 1, 661, 7, 7, 9, 6, 433, 3184, 14, 12, 6, 1, 358, 5, 1, 6813, 2538, 1064, 9, 2711, 1421, 20, 538, 32, 4636, 2468, 4, 1, 1208, 117, 29, 1, 7017, 25, 2970, 2, 391, 34, 6, 21, 299, 20, 1, 4910, 7364, 538, 6, 344, 5, 106, 8161, 5050, 7889, 2453, 2, 51, 34, 327, 9106, 7365, 2, 8697, 23, 110, 225, 243, 7, 7, 10, 58, 131, 1, 280, 1324, 4, 1, 119, 6, 693, 5, 1, 192, 12, 9, 269, 117, 79, 276, 589, 3024, 834, 180, 1320, 4161, 15, 2523, 1243, 834, 1443, 834, 887, 3184, 149, 954, 183, 1, 86, 398, 10, 123, 210, 3241, 68, 14, 34, 1637, 9, 13, 2239, 10, 413, 131, 10, 13, 1592, 15, 9, 18, 14, 10, 287, 51, 10, 1417, 3, 1280, 15, 3184, 2, 189, 5, 1, 299, 2046, 4, 2150, 570, 21, 39, 570, 18, 7658, 7154, 5010, 26, 2983, 41, 15, 3, 6904, 504, 20, 642, 2, 76, 243, 16, 9, 69, 7598, 651, 710, 6904, 109, 662, 82, 1208, 693, 5, 65, 574, 4, 920, 2021, 38, 1208, 559, 147, 3184, 22, 200, 426, 3819, 16, 48, 6, 3314, 805, 1603, 43, 22, 67, 76, 8, 1228, 16, 125, 4103, 486]\n",
      "[3, 393, 120, 353, 7, 7, 1, 1385, 2977, 6, 52, 52, 155, 55, 2381, 1582, 2, 411, 3, 2, 530, 282, 4, 1847, 5, 1, 438, 412, 7, 7, 1, 150, 23, 568, 69, 2274, 498, 4571, 21, 61, 45, 189, 29, 1, 18, 28, 45, 29, 1, 2294, 175, 3336, 96, 22, 67, 371, 63, 1, 791, 9719, 31, 1, 1825, 5, 7366, 6594, 21, 61, 6, 9, 69, 278, 1, 147, 18, 9, 6, 3, 407, 2, 2406, 412, 3, 4339, 353, 42, 27, 4, 1, 78, 4, 202, 2, 24, 114, 7, 7, 1, 1847, 62, 270, 344, 16, 1, 120, 177, 1, 1029, 4, 1, 2924, 60, 248, 71, 356, 1, 2206, 3127, 1289, 1192, 91, 4911, 9, 297, 20, 260, 1830, 2, 260, 4592, 583, 16, 1, 134, 3690, 2, 2, 1, 730, 583, 4, 65, 1054, 16, 170, 2297, 23, 1977, 69, 221]\n",
      "[10, 190, 11, 13, 3, 393, 95, 5, 1155, 55, 20, 3, 96, 879, 1494, 2657, 1241, 8, 1, 903, 769, 2, 147, 3, 649, 2333, 202, 1, 111, 6, 4086, 18, 1, 410, 6, 1915, 2, 1, 102, 23, 1485, 57, 1, 69, 6126, 6686, 1574, 494, 136, 47, 200, 26, 680, 50, 33, 959, 11, 6, 21, 1026, 220, 230, 2917, 5196, 10, 190, 9, 13, 3059, 12, 2971, 2050, 6, 130, 1403, 8, 1139, 4, 1, 396, 106, 4, 176, 25, 2079, 5, 112, 7, 7, 11, 13, 1, 88, 482, 1451, 30, 27, 4, 1317, 8, 153, 3024, 10, 131, 3, 2121, 136, 198, 110, 75, 1508, 16, 8927, 8, 11, 59, 1323, 5, 1260, 175, 40, 1257, 1428, 2, 5078, 203, 82, 3, 848, 18, 3611, 186, 257, 7, 7, 11, 200, 21, 26, 1, 7241, 5176, 4, 24, 628, 18, 9, 13, 71, 2244, 2930, 2, 51, 218, 71, 2658, 3, 78, 202, 5, 139, 63, 16, 350]\n",
      "[688, 222, 3, 236, 117, 3, 120, 420, 3639, 1251, 222, 3, 1024, 8, 24, 4299, 24, 814, 23, 1000, 29, 1, 55, 7, 7, 11, 17, 6, 7833, 71, 3, 1826, 1313, 2, 1117, 3639, 1094, 5, 426, 5596, 2, 504, 1, 1024, 7, 7, 584, 86, 4, 29, 50, 337, 166, 5, 94, 3, 19, 22, 206, 1166, 43, 92, 3, 704, 38, 3, 449, 14, 3, 449, 1, 17, 6, 1712, 814, 23, 6905, 37, 8, 144, 114, 2, 91, 73, 25, 3639, 16, 24, 4299, 60, 456, 4104, 29, 1, 19, 10, 862, 5, 63, 3, 742, 17, 2, 298, 10, 287, 3, 449, 16, 47, 3864, 704, 3274, 7, 7, 338, 41, 4, 156, 39, 15, 1, 69, 394, 814, 4709, 3303, 14, 15, 1, 644, 16, 3639, 39, 2775, 93]\n",
      "[112, 8, 1, 55, 4, 290, 6, 3, 2141, 1427, 19, 5, 103, 439, 1567, 176, 3, 4270, 3325, 42, 395, 4463, 11, 6, 3, 17, 12, 184, 5, 26, 997, 176, 48, 290, 660, 2, 1007, 77, 5, 83, 8, 1, 279, 1141, 73, 2495, 7, 7, 11, 109, 3, 7105, 20, 1, 1877, 288, 42, 1, 167, 768, 1, 164, 1, 205, 5, 1, 1001, 55, 168, 874, 117, 29, 132, 279, 102, 908, 2, 3777, 252, 27, 6, 3256, 8, 27, 95, 38, 157, 5, 1, 365, 401, 18, 54, 27, 184, 5, 118, 1, 932, 220, 4, 2918, 1, 19, 45, 3, 3389, 163, 73, 23, 607, 5, 63, 85, 132, 83, 421, 2, 1, 181, 33, 421, 8, 65, 199, 7, 7, 1, 61, 148, 27, 217, 41, 4, 29, 132, 3451, 8, 1, 435, 6, 1, 279, 5799, 4, 4780, 252, 27, 3, 191, 538, 6, 21, 621, 1, 116, 274, 8, 60, 395, 4463, 165, 4494, 14, 27, 6, 1, 417, 16, 88, 4, 1, 83, 73, 2495, 7, 7, 1, 113, 6, 49, 464, 439, 459, 1339, 6088, 3949, 2873, 498, 7060, 2, 1, 370, 4, 1, 1025, 174, 94, 132, 102, 215, 1126, 7, 7, 73, 641, 439, 49, 2051, 2, 15, 24, 365, 158]\n",
      "[239, 56, 29, 55, 521, 17, 3, 64, 4, 3889, 2, 8013, 5, 3, 3574, 1148, 18, 44, 21, 5276, 38, 348, 9, 39, 110, 217, 155, 467, 56, 263, 107, 9, 47, 1107, 38, 51, 209, 8, 1, 238, 2421, 153, 840, 241, 981, 1723, 5, 56, 519, 2, 4118, 2095, 8, 27, 4, 40, 52, 171, 371, 2203, 578, 6, 3, 3029, 1, 351, 23, 14, 7890, 546, 51, 37, 1870, 53, 71, 466, 18, 12, 61, 162, 93, 51, 245, 5, 103, 2, 1, 4233, 561, 8370, 5, 772, 1462, 8, 1, 181, 2, 464, 40, 199, 5277, 6, 828, 2, 6127, 43, 10, 66, 3, 2574, 3542, 3397, 29, 26, 53, 15, 11, 17]\n",
      "[10, 247, 58, 37, 5, 63, 3, 9015, 4, 3, 53, 2047, 204, 16, 1, 5051, 33, 25, 622, 9, 58, 739, 141, 1, 553, 2411, 8, 68, 10, 2160, 53, 20, 317, 2, 452, 240, 2, 16, 70, 56, 6814, 170, 1237, 22, 25, 56, 2058, 15, 3, 7201, 4, 3, 168, 1641, 2347, 73, 362, 3, 665, 4, 1055, 8, 240, 2, 11, 58, 158, 15, 3, 181, 4, 464, 985, 1172, 429, 31, 1, 95, 1355, 22, 15, 32, 37, 11, 5, 635, 106, 42, 240, 2, 1, 106, 97, 34, 99, 95, 10, 262, 198, 189, 48, 10, 2931, 131, 58, 26, 331, 5, 339, 47, 51, 913, 809, 42, 1641, 2347, 43, 56, 58, 26, 156, 409, 58, 22, 379, 68, 38, 566, 68, 41, 5, 26, 8, 798, 2, 25, 68, 5, 4863, 43, 11, 6, 34, 91, 10, 206, 139, 34, 1573, 77, 9]\n",
      "[11, 119, 13, 32, 491, 1452, 4133, 321, 8, 1, 1733, 50, 9, 86, 3110, 1, 86, 702, 38, 723, 153, 70, 513, 18, 177, 3407, 122, 100, 12, 31, 5126, 1, 119, 13, 21, 62, 152, 1543, 2, 44, 3732, 92, 6056, 1069, 5, 1, 597, 451, 4, 55, 9, 6, 622, 7, 7, 44, 371, 85, 225, 11, 119, 45, 3014, 1, 490, 6, 2334, 74, 1, 367, 23, 216, 14, 74, 43, 21, 15, 1, 2643, 427, 4, 1, 2844, 8371, 11, 119, 239, 589, 130, 26, 20, 1, 903, 10, 165, 9, 34, 249, 5, 262, 12, 1, 167, 4940, 12, 524, 6378, 1, 212, 174, 81, 2508, 1, 1143, 4, 12, 1559, 85, 67, 27, 2425, 138, 3575, 2, 91, 63, 1118, 5, 5052, 9, 16, 138, 6687, 10, 436, 10, 206, 197, 230, 405, 41, 4, 1173, 15, 1, 212, 174, 12, 90, 11, 119, 138, 3, 643, 1007, 14, 9, 6, 146, 1, 119, 6, 39, 372, 10, 185, 262, 44, 130, 20, 1, 903]\n",
      "[8458, 31, 1, 1161, 786, 42, 11, 19, 20, 133, 10, 13, 256, 929, 5, 147, 11, 19, 74, 1408, 198, 107, 104, 2, 11, 6, 371, 27, 4, 1, 246, 4, 93, 44, 372, 8, 216, 170, 95, 791, 1787, 773, 788, 738, 1, 630, 61, 605, 3, 865, 679, 3042, 6, 253, 54, 340, 71, 659, 209, 1, 19, 285, 691, 2, 1637, 2, 6, 348, 8, 1, 1529, 1703, 25, 10, 75, 34, 673, 5, 63, 1, 127, 896, 4, 3, 19, 7, 7, 1, 61, 148, 12, 9842, 68, 740, 11, 3, 307, 569, 6, 4572, 136, 11, 6, 225, 36, 24, 116, 241, 28, 30, 224, 184, 5, 26, 232, 3, 226, 4, 32, 777, 27, 15, 61]\n",
      "[43, 22, 37, 212, 5312, 5800, 2151, 22, 80, 37, 11, 17, 43, 22, 23, 186, 38, 155, 91, 22, 80, 112, 11, 17, 603, 57, 56, 1604, 425, 9, 7, 7, 78, 1225]\n"
     ]
    }
   ],
   "source": [
    "# Display some x values \n",
    "for i in range(10):\n",
    "    print(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences to ensure all sequences have the same length (500 in this case)\n",
    "X = pad_sequences(X, maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  12    6    1  358    5    1 6813 2538 1064    9 2711 1421   20  538\n",
      "   32 4636 2468    4    1 1208  117   29    1 7017   25 2970    2  391\n",
      "   34    6   21  299   20    1 4910 7364  538    6  344    5  106 8161\n",
      " 5050 7889 2453    2   51   34  327 9106 7365    2 8697   23  110  225\n",
      "  243    7    7   10   58  131    1  280 1324    4    1  119    6  693\n",
      "    5    1  192   12    9  269  117   79  276  589 3024  834  180 1320\n",
      " 4161   15 2523 1243  834 1443  834  887 3184  149  954  183    1   86\n",
      "  398   10  123  210 3241   68   14   34 1637    9   13 2239   10  413\n",
      "  131   10   13 1592   15    9   18   14   10  287   51   10 1417    3\n",
      " 1280   15 3184    2  189    5    1  299 2046    4 2150  570   21   39\n",
      "  570   18 7658 7154 5010   26 2983   41   15    3 6904  504   20  642\n",
      "    2   76  243   16    9   69 7598  651  710 6904  109  662   82 1208\n",
      "  693    5   65  574    4  920 2021   38 1208  559  147 3184   22  200\n",
      "  426 3819   16   48    6 3314  805 1603   43   22   67   76    8 1228\n",
      "   16  125 4103  486]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    3  393  120  353    7    7\n",
      "    1 1385 2977    6   52   52  155   55 2381 1582    2  411    3    2\n",
      "  530  282    4 1847    5    1  438  412    7    7    1  150   23  568\n",
      "   69 2274  498 4571   21   61   45  189   29    1   18   28   45   29\n",
      "    1 2294  175 3336   96   22   67  371   63    1  791 9719   31    1\n",
      " 1825    5 7366 6594   21   61    6    9   69  278    1  147   18    9\n",
      "    6    3  407    2 2406  412    3 4339  353   42   27    4    1   78\n",
      "    4  202    2   24  114    7    7    1 1847   62  270  344   16    1\n",
      "  120  177    1 1029    4    1 2924   60  248   71  356    1 2206 3127\n",
      " 1289 1192   91 4911    9  297   20  260 1830    2  260 4592  583   16\n",
      "    1  134 3690    2    2    1  730  583    4   65 1054   16  170 2297\n",
      "   23 1977   69  221]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0   10  190   11   13    3  393\n",
      "   95    5 1155   55   20    3   96  879 1494 2657 1241    8    1  903\n",
      "  769    2  147    3  649 2333  202    1  111    6 4086   18    1  410\n",
      "    6 1915    2    1  102   23 1485   57    1   69 6126 6686 1574  494\n",
      "  136   47  200   26  680   50   33  959   11    6   21 1026  220  230\n",
      " 2917 5196   10  190    9   13 3059   12 2971 2050    6  130 1403    8\n",
      " 1139    4    1  396  106    4  176   25 2079    5  112    7    7   11\n",
      "   13    1   88  482 1451   30   27    4 1317    8  153 3024   10  131\n",
      "    3 2121  136  198  110   75 1508   16 8927    8   11   59 1323    5\n",
      " 1260  175   40 1257 1428    2 5078  203   82    3  848   18 3611  186\n",
      "  257    7    7   11  200   21   26    1 7241 5176    4   24  628   18\n",
      "    9   13   71 2244 2930    2   51  218   71 2658    3   78  202    5\n",
      "  139   63   16  350]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0  688  222    3  236  117    3\n",
      "  120  420 3639 1251  222    3 1024    8   24 4299   24  814   23 1000\n",
      "   29    1   55    7    7   11   17    6 7833   71    3 1826 1313    2\n",
      " 1117 3639 1094    5  426 5596    2  504    1 1024    7    7  584   86\n",
      "    4   29   50  337  166    5   94    3   19   22  206 1166   43   92\n",
      "    3  704   38    3  449   14    3  449    1   17    6 1712  814   23\n",
      " 6905   37    8  144  114    2   91   73   25 3639   16   24 4299   60\n",
      "  456 4104   29    1   19   10  862    5   63    3  742   17    2  298\n",
      "   10  287    3  449   16   47 3864  704 3274    7    7  338   41    4\n",
      "  156   39   15    1   69  394  814 4709 3303   14   15    1  644   16\n",
      " 3639   39 2775   93]\n",
      "[1567  176    3 4270 3325   42  395 4463   11    6    3   17   12  184\n",
      "    5   26  997  176   48  290  660    2 1007   77    5   83    8    1\n",
      "  279 1141   73 2495    7    7   11  109    3 7105   20    1 1877  288\n",
      "   42    1  167  768    1  164    1  205    5    1 1001   55  168  874\n",
      "  117   29  132  279  102  908    2 3777  252   27    6 3256    8   27\n",
      "   95   38  157    5    1  365  401   18   54   27  184    5  118    1\n",
      "  932  220    4 2918    1   19   45    3 3389  163   73   23  607    5\n",
      "   63   85  132   83  421    2    1  181   33  421    8   65  199    7\n",
      "    7    1   61  148   27  217   41    4   29  132 3451    8    1  435\n",
      "    6    1  279 5799    4 4780  252   27    3  191  538    6   21  621\n",
      "    1  116  274    8   60  395 4463  165 4494   14   27    6    1  417\n",
      "   16   88    4    1   83   73 2495    7    7    1  113    6   49  464\n",
      "  439  459 1339 6088 3949 2873  498 7060    2    1  370    4    1 1025\n",
      "  174   94  132  102  215 1126    7    7   73  641  439   49 2051    2\n",
      "   15   24  365  158]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0  239   56\n",
      "   29   55  521   17    3   64    4 3889    2 8013    5    3 3574 1148\n",
      "   18   44   21 5276   38  348    9   39  110  217  155  467   56  263\n",
      "  107    9   47 1107   38   51  209    8    1  238 2421  153  840  241\n",
      "  981 1723    5   56  519    2 4118 2095    8   27    4   40   52  171\n",
      "  371 2203  578    6    3 3029    1  351   23   14 7890  546   51   37\n",
      " 1870   53   71  466   18   12   61  162   93   51  245    5  103    2\n",
      "    1 4233  561 8370    5  772 1462    8    1  181    2  464   40  199\n",
      " 5277    6  828    2 6127   43   10   66    3 2574 3542 3397   29   26\n",
      "   53   15   11   17]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0   10  247   58   37    5   63    3\n",
      " 9015    4    3   53 2047  204   16    1 5051   33   25  622    9   58\n",
      "  739  141    1  553 2411    8   68   10 2160   53   20  317    2  452\n",
      "  240    2   16   70   56 6814  170 1237   22   25   56 2058   15    3\n",
      " 7201    4    3  168 1641 2347   73  362    3  665    4 1055    8  240\n",
      "    2   11   58  158   15    3  181    4  464  985 1172  429   31    1\n",
      "   95 1355   22   15   32   37   11    5  635  106   42  240    2    1\n",
      "  106   97   34   99   95   10  262  198  189   48   10 2931  131   58\n",
      "   26  331    5  339   47   51  913  809   42 1641 2347   43   56   58\n",
      "   26  156  409   58   22  379   68   38  566   68   41    5   26    8\n",
      "  798    2   25   68    5 4863   43   11    6   34   91   10  206  139\n",
      "   34 1573   77    9]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "   11  119   13   32  491 1452 4133  321    8    1 1733   50    9   86\n",
      " 3110    1   86  702   38  723  153   70  513   18  177 3407  122  100\n",
      "   12   31 5126    1  119   13   21   62  152 1543    2   44 3732   92\n",
      " 6056 1069    5    1  597  451    4   55    9    6  622    7    7   44\n",
      "  371   85  225   11  119   45 3014    1  490    6 2334   74    1  367\n",
      "   23  216   14   74   43   21   15    1 2643  427    4    1 2844 8371\n",
      "   11  119  239  589  130   26   20    1  903   10  165    9   34  249\n",
      "    5  262   12    1  167 4940   12  524 6378    1  212  174   81 2508\n",
      "    1 1143    4   12 1559   85   67   27 2425  138 3575    2   91   63\n",
      " 1118    5 5052    9   16  138 6687   10  436   10  206  197  230  405\n",
      "   41    4 1173   15    1  212  174   12   90   11  119  138    3  643\n",
      " 1007   14    9    6  146    1  119    6   39  372   10  185  262   44\n",
      "  130   20    1  903]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0 8458   31    1 1161  786   42   11\n",
      "   19   20  133   10   13  256  929    5  147   11   19   74 1408  198\n",
      "  107  104    2   11    6  371   27    4    1  246    4   93   44  372\n",
      "    8  216  170   95  791 1787  773  788  738    1  630   61  605    3\n",
      "  865  679 3042    6  253   54  340   71  659  209    1   19  285  691\n",
      "    2 1637    2    6  348    8    1 1529 1703   25   10   75   34  673\n",
      "    5   63    1  127  896    4    3   19    7    7    1   61  148   12\n",
      " 9842   68  740   11    3  307  569    6 4572  136   11    6  225   36\n",
      "   24  116  241   28   30  224  184    5   26  232    3  226    4   32\n",
      "  777   27   15   61]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0   43   22\n",
      "   37  212 5312 5800 2151   22   80   37   11   17   43   22   23  186\n",
      "   38  155   91   22   80  112   11   17  603   57   56 1604  425    9\n",
      "    7    7   78 1225]\n"
     ]
    }
   ],
   "source": [
    "# Display some x values after padding\n",
    "for i in range(10):\n",
    "    print(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nick8\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the RNN model using TensorFlow\n",
    "model = tf.keras.Sequential([ # Defines a sequential model using TensorFlow's Keras API. A sequential model is a stack of neural network layers.\n",
    "    tf.keras.layers.Embedding(input_dim=10000, output_dim=32, input_length=200), # This layer creates word embeddings for the input sequences. Each integer representation of word is mapped to a fixed-length numerical vector.\n",
    "    tf.keras.layers.SimpleRNN(64), # This layer defines a simple recurrent neural network (RNN) with 64 units in each neuron.\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid') # This layer is a fully connected dense layer with one unit and sigmoid activation function for binary classification.\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nick8\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile the model with the Adam optimizer, binary cross-entropy loss function, and accuracy metric.\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\nick8\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\nick8\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "625/625 [==============================] - 21s 31ms/step - loss: 0.5489 - accuracy: 0.6965 - val_loss: 0.3823 - val_accuracy: 0.8439\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 21s 33ms/step - loss: 0.3504 - accuracy: 0.8532 - val_loss: 0.3905 - val_accuracy: 0.8332\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 23s 38ms/step - loss: 0.6055 - accuracy: 0.6855 - val_loss: 0.5055 - val_accuracy: 0.7482\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.3262 - accuracy: 0.8632 - val_loss: 0.3515 - val_accuracy: 0.8508\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 22s 36ms/step - loss: 0.2687 - accuracy: 0.8937 - val_loss: 0.3461 - val_accuracy: 0.8544\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the training data for 5 epochs with a batch size of 64.\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 0.3461 - accuracy: 0.8544\n",
      "Test Loss: 0.3460632860660553\n",
      "Test Accuracy: 0.8543999791145325\n"
     ]
    }
   ],
   "source": [
    "#  Evaluate the model on the test data and computes the test loss and accuracy.\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

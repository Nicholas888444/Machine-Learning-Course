{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55a6c91b-39ad-42a8-a3da-561208df8ac3",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405e556f-8d41-4d60-9540-52576f0e1c11",
   "metadata": {},
   "source": [
    "In this tutorial, we will build a logistic regression model to predict diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbc527a-a225-4543-add1-71a6b3899752",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646054d5-8184-4aa6-a1f5-896d4cf6e0d6",
   "metadata": {},
   "source": [
    "We will use the Pima Indians Diabetes Database, which can be found at https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database.\n",
    "\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2391c76e-a0d4-4035-94ee-f529a736f52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from my github link\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/yangliuiuk/data/main/diabetes.csv\")\n",
    "\n",
    "# Explore the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "829f657f-a81c-4c7b-bc84-f557975d3000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51053185-1d66-417e-9ca4-050a042a5989",
   "metadata": {},
   "source": [
    "### Dependent and Independent Variable\n",
    "We aim to predict the 'Outcome' column based on other columns. The 'Outcome' feature indicates whether a person has diabete.\n",
    "\n",
    "So, the 'Outcome' is the dependent variable and other variables are independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c73eb23-1999-4809-9e0e-4b1f410da265",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bd1432-af7a-4a05-93f5-9034d30a3657",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "For any classification problem, we first need to explore the class distribution. If the class distribution is imbalanced, then the trained model will be biased. \n",
    "\n",
    "For instance, if 80% of data points are positive and 20% are negative, a model that simply predicts every data point as positive can yeild an 80% accuracy. In this case, an high accuracy doesn't mean the model performs good.\n",
    "\n",
    "If the class distribution is imbalanced, oversampling or undersampling is needed to reconstruct the class distribution.\n",
    "\n",
    "First, we check the distribution of the dependend variable 'Outcome'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ea96f72-605a-4bd3-8c15-013112e490cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "0    500\n",
       "1    268\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4227d482-0bc5-4e92-a4d9-d3510543afa9",
   "metadata": {},
   "source": [
    "### Oversamping\n",
    "The above result shows that there are 500 negative instances vs 268 positive instances. The class distribution is inbalanced. We will use oversampling to address this problem.\n",
    "\n",
    "Oversampling and undersampling are techniques used in the field of imbalanced classification to address the problem of class imbalance, where one class has significantly fewer samples than the other(s). These techniques are used to balance the class distribution in the dataset, which can improve the performance of machine learning models, particularly for minority classes.\n",
    "\n",
    "Oversampling involves increasing the number of instances in the minority class(es) by generating synthetic samples or replicating existing ones. This is done to balance the class distribution and provide the model with more examples of the minority class. \n",
    "\n",
    "Undersampling involves reducing the number of instances in the majority class(es) to balance the class distribution. This is typically done by randomly selecting a subset of samples from the majority class. Undersampling aims to mitigate the impact of class imbalance by reducing the dominance of the majority class. \n",
    "\n",
    "Both oversampling and undersampling have their advantages and drawbacks. Oversampling can increase the risk of overfitting, especially when using naive approaches like random oversampling. Undersampling can discard potentially useful information from the majority class, leading to loss of data. \n",
    "\n",
    "Because the number of data instances is small in this dataset, so we prefer oversamping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "454c215e-0d5f-41c9-91af-b5a30861bc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\ly768\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\ly768\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imblearn) (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ly768\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\ly768\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\ly768\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ly768\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ly768\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (3.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c88a79b8-9e17-41e7-8fce-2b513cd96fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               1000 non-null   int64  \n",
      " 1   Glucose                   1000 non-null   int64  \n",
      " 2   BloodPressure             1000 non-null   int64  \n",
      " 3   SkinThickness             1000 non-null   int64  \n",
      " 4   Insulin                   1000 non-null   int64  \n",
      " 5   BMI                       1000 non-null   float64\n",
      " 6   DiabetesPedigreeFunction  1000 non-null   float64\n",
      " 7   Age                       1000 non-null   int64  \n",
      "dtypes: float64(2), int64(6)\n",
      "memory usage: 62.6 KB\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Series name: Outcome\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "1000 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 7.9 KB\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
    "\n",
    "X_resampled.info()\n",
    "y_resampled.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963ae13f-9604-4e14-999a-90fbeadebc55",
   "metadata": {},
   "source": [
    "### Split Data in Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7453d8b4-a4d8-4838-873f-c00f73f26c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b22b41-dc0b-4090-a275-cbae1b190d25",
   "metadata": {},
   "source": [
    "### Build and train a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed7c418b-8925-41c7-8d16-af2198922805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=16)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=16)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression(random_state=16)\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed273632-a342-4313-9cdf-56184307054b",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ab67da8-3bc8-4bae-873f-87e63687b0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72, 27],\n",
       "       [26, 75]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on testing set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1b42427-4f6d-4594-8c74-b8445510e6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.735\n",
      "Precision: 0.7352941176470589\n",
      "Recall: 0.7425742574257426\n",
      "F1 Score: 0.7389162561576355\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy, precision, recall, and F1 score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "y_pred = logreg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ad6be2-6c5a-4fb8-bf87-ff304dd9beee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
